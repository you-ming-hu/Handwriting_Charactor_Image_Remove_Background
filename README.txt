題目:
	玉山手寫辨識比賽


問題:
	資料集數量不多，每個中文字大約只有60張圖片，且品質參差


發現:
	辨識圖片大多為黑/藍字、白色底、紅色框線組成。

想法:
	基於上述的發現，我認為應該存在一個前處理的方法，可以提升圖片輸入的品質，同時該方法也能納入深度學習的框架中。
	最直覺的解決方案應該是將彩圖轉為灰階，同時去除雜訊(紅色外框等)，製作類是MNIST那樣的資料集。
	如果存在一個這樣的前處理輸入方法，應該可以讓機器更專注於學習需要的特徵，在較少量的資料上也能學習到所需的特徵且不受雜訊影響。

作法:
	1.GMM Model
	由於圖片的顏色分布相對單純，我認為圖片中文字在RGB空間中是可以分離的。
	先試著採用GMM的模型在RGB空間上粗略的把文字的部分分割出來。
	參考文獻:https://ir.nctu.edu.tw/bitstream/11536/68068/7/251107.pdf?fbclid=IwAR2CInLudrncqHSadtydH3CkjtnOKlAuVw_NuJeV_VBLQsFHMG3thabpplc
	2.Refine Gray Image
	經過GMM Model轉換成灰階的圖片仍然存在一些雜訊或是移除掉部分文字，用Photoshop以人工的方式將剩下的雜訊消除與補回缺失部分
	3.CNN Model
	由於GMM Model在分割圖片上仍存在一些極限，無法適當分割所有圖片，
	而且受限於GMM的演算法是迭代的運算，在效能上也無法平行處理，甚至可能沒有辦法和tensorflow相容
	或許利用深度學習可以完全取代GMM Model的運算，甚至透過人工修整的圖片，學習到更高層次的特徵，以利圖片轉換，同時獲得平行運算的效能優勢。
	另外該模型也可以pretrain好之後，也可以作為輸入的前處理，接合在辨識模型之前，整個模型都能在tensorflow框架內完成。
	
結論:
	1.利用本資料集的特色，先用GMM Model做簡單的去背，以減少後續人工修整圖片的負擔，加速去背轉灰階的作業速度。
	2.將原本的RGB圖片與修整好的灰階圖片送給深度學習做轉換，在300對以內的圖片作為訓練資料，就可以獲得能夠取代GMM Model的結果，同時減少運算時間。